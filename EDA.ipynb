{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wNP0nicY5mHX"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "# -----------------------------\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make plots look reasonable in notebooks\n",
        "plt.rcParams.update({'figure.figsize': (10, 5), 'figure.dpi': 100})"
      ],
      "metadata": {
        "id": "tPpOAcWL55h2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Config (edit these)\n",
        "# -----------------------------\n",
        "# Either set DATA_PATH to a local CSV file, or DATA_URL to a publicly reachable CSV URL.\n",
        "DATA_PATH = 'food_service_data.csv' # <-- change this to your filename if needed\n",
        "DATA_URL = None # e.g. 'https://raw.githubusercontent.com/your/repo/file.csv'\n",
        "OUTPUT_DIR = 'eda_outputs'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "AjC5ajlN5_5L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def load_data(path=None, url=None):\n",
        "  if url:\n",
        "    df = pd.read_csv(url, parse_dates=['date'], dayfirst=False)\n",
        "  elif path and Path(path).exists():\n",
        "   df = pd.read_csv(path, parse_dates=['date'], dayfirst=False)\n",
        "  else:\n",
        "   raise FileNotFoundError('Please provide a valid DATA_PATH or DATA_URL')\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def overview(df):\n",
        "    print('\\n=== Dataframe shape ===')\n",
        "    print(df.shape)\n",
        "    print('\\n=== Head ===')\n",
        "    print(df.head())\n",
        "    print('\\n=== Dtypes ===')\n",
        "    print(df.dtypes)\n",
        "    print('\\n=== Missing values per column ===')\n",
        "    print(df.isna().sum())\n",
        ""
      ],
      "metadata": {
        "id": "q7MmlwjC6BI3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df = load_data(DATA_PATH if Path(DATA_PATH).exists() else None, DATA_URL)\n",
        "except Exception as e:\n",
        "    print('Error loading data:', e)\n",
        "    # Create an empty example dataframe so subsequent cells won't crash while developing\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "# If the user loaded a real dataframe, continue\n",
        "if not df.empty:\n",
        "        overview(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNVDUjaF6BB2",
        "outputId": "83314413-eead-4c63-cfbc-4d2625ce4c04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading data: Please provide a valid DATA_PATH or DATA_URL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial cleaning & type corrections\n",
        "# -----------------------------\n",
        "# Standardize column names (strip, lower)\n",
        "df.columns = [c.strip() for c in df.columns]"
      ],
      "metadata": {
        "id": "YvEdMt5D6A-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure expected columns exist; provide helpful warnings if not\n",
        "expected_cols = ['ID','date','meals_served','kitchen_staff','temperature_C',\n",
        "'humidity_percent','day_of_week','special_event','past_waste_kg',\n",
        "'staff_experience','waste_category']"
      ],
      "metadata": {
        "id": "ZkVKSVaC6921"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt to map similar names if needed\n",
        "col_map = {}\n",
        "for col in df.columns:\n",
        "    low = col.lower()\n",
        "    if low in ['id', 'identifier']:\n",
        "        col_map[col] = 'ID'\n",
        "    elif 'date' in low:\n",
        "        col_map[col] = 'date'\n",
        "    elif 'meal' in low:\n",
        "        col_map[col] = 'meals_served'\n",
        "    elif 'kitchen' in low and 'staff' in low:\n",
        "        col_map[col] = 'kitchen_staff'\n",
        "    elif 'temperature' in low:\n",
        "        col_map[col] = 'temperature_C'\n",
        "    elif 'humid' in low:\n",
        "        col_map[col] = 'humidity_percent'\n",
        "    elif 'day' in low and 'week' in low:\n",
        "        col_map[col] = 'day_of_week'\n",
        "    elif 'special' in low and 'event' in low:\n",
        "        col_map[col] = 'special_event'\n",
        "    elif 'past' in low and 'waste' in low:\n",
        "        col_map[col] = 'past_waste_kg'\n",
        "    elif 'experience' in low or 'exp' in low:\n",
        "        col_map[col] = 'staff_experience'\n",
        "    elif 'waste_category' in low or ('waste' in low and 'cat' in low):\n",
        "        col_map[col] = 'waste_category'\n",
        "\n",
        "# Rename columns if any mapping exists\n",
        "if col_map:\n",
        "    df = df.rename(columns=col_map)\n"
      ],
      "metadata": {
        "id": "XcMoa2c669za"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date\n",
        "if 'date' in df.columns:\n",
        "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "\n",
        "\n",
        "# Numeric conversions\n",
        "for num_col in ['meals_served','kitchen_staff','temperature_C','humidity_percent','past_waste_kg','day_of_week']:\n",
        "    if num_col in df.columns:\n",
        "        df[num_col] = pd.to_numeric(df[num_col], errors='coerce')\n",
        "\n",
        "\n",
        "# Binary column corrections\n",
        "if 'special_event' in df.columns:\n",
        "    # map common variants\n",
        "    df['special_event'] = df['special_event'].map({True:1, False:0, 'Yes':1, 'No':0, 'Y':1, 'N':0}).fillna(df['special_event'])\n",
        "    df['special_event'] = pd.to_numeric(df['special_event'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "\n",
        "# Strip whitespace in categorical columns\n",
        "for cat in ['staff_experience','waste_category']:\n",
        "    if cat in df.columns:\n",
        "        df[cat] = df[cat].astype(str).str.strip().replace({'nan': np.nan})\n"
      ],
      "metadata": {
        "id": "w_s16ssR69wf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values handling strategy (logged)\n",
        "# -----------------------------\n",
        "missing_summary = df.isna().sum()\n",
        "print('\\nMissing summary:\\n', missing_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVBbzvln69ts",
        "outputId": "6fc686ac-98b4-44cd-927a-f5d0026d5d42"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing summary:\n",
            " Series([], dtype: float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows missing date or meals_served (if they are very few)\n",
        "if 'date' in df.columns and 'meals_served' in df.columns:\n",
        "    n_before = df.shape[0]\n",
        "    df = df.dropna(subset=['date', 'meals_served'])\n",
        "    print(f'Dropped {n_before - df.shape[0]} rows missing date or meals_served')\n"
      ],
      "metadata": {
        "id": "ocecUlKL69q0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For numeric fields, impute median if missing but keep a flag\n",
        "for c in ['temperature_C','humidity_percent','past_waste_kg','kitchen_staff']:\n",
        "    if c in df.columns:\n",
        "        miss = df[c].isna().sum()\n",
        "        if miss > 0:\n",
        "            df[c + '_missing_flag'] = df[c].isna().astype(int)\n",
        "            df[c] = df[c].fillna(df[c].median())\n",
        "            print(f'Imputed {miss} missing values in {c} with median')\n"
      ],
      "metadata": {
        "id": "I6t4jyPr69ow"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For categorical columns\n",
        "for c in ['staff_experience','waste_category']:\n",
        "    if c in df.columns:\n",
        "        df[c] = df[c].fillna('Unknown')\n"
      ],
      "metadata": {
        "id": "U_9WAotj69nC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Duplicates\n",
        "# -----------------------------\n",
        "n_dup = df.duplicated().sum()\n",
        "print(f'Found {n_dup} duplicate rows')\n",
        "if n_dup > 0:\n",
        "    df = df.drop_duplicates()\n",
        "    print('Dropped duplicate rows')\n",
        "\n",
        "# -----------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNCR_RPc69jz",
        "outputId": "d4c61f90-91bf-4551-b213-1213172cef90"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 duplicate rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering\n",
        "# -----------------------------\n",
        "if 'date' in df.columns:\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['day'] = df['date'].dt.day\n",
        "    df['weekday_name'] = df['date'].dt.day_name()\n"
      ],
      "metadata": {
        "id": "fjuYExEA69gL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create staff_level categories (low/medium/high) based on quantiles\n",
        "if 'kitchen_staff' in df.columns:\n",
        "    quantiles = df['kitchen_staff'].quantile([0.33, 0.66]).values\n",
        "\n",
        "    def staff_level(x):\n",
        "        if x <= quantiles[0]:\n",
        "            return 'low'\n",
        "        elif x <= quantiles[1]:\n",
        "            return 'medium'\n",
        "        else:\n",
        "            return 'high'\n",
        "\n",
        "    df['staff_level'] = df['kitchen_staff'].apply(staff_level)\n"
      ],
      "metadata": {
        "id": "3hLochXK69dI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics\n",
        "# -----------------------------\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "if numeric_cols:  # only proceed if we have numeric columns\n",
        "    print('\\nNumeric summary:')\n",
        "    display_df = df[numeric_cols].describe().T\n",
        "    print(display_df)\n",
        "    display_df.to_csv(os.path.join(OUTPUT_DIR, 'numeric_summary.csv'))\n",
        "else:\n",
        "    print(\"No numeric columns found in the dataframe.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FnrP9nJ7jUL",
        "outputId": "946fee2a-9fa8-40bc-db63-a87266f3da78"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No numeric columns found in the dataframe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizations\n",
        "# -----------------------------\n",
        "# Histograms for key numerical columns\n",
        "plot_cols = ['meals_served','temperature_C','humidity_percent','past_waste_kg']\n",
        "for c in plot_cols:\n",
        "    if c in df.columns:\n",
        "        plt.figure()\n",
        "        sns.histplot(df[c].dropna(), kde=True)\n",
        "        plt.title(f'Distribution of {c}')\n",
        "        plt.xlabel(c)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f'hist_{c}.png'))\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "HliV_NEx7jQd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplots to detect outliers\n",
        "for c in ['meals_served','past_waste_kg']:\n",
        "    if c in df.columns:\n",
        "        plt.figure()\n",
        "        sns.boxplot(x=df[c].dropna())\n",
        "        plt.title(f'Boxplot of {c}')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f'box_{c}.png'))\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "vHV0pFhK7jNh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar plots for categorical variables\n",
        "for c in ['staff_experience','waste_category','staff_level']:\n",
        "    if c in df.columns:\n",
        "        plt.figure(figsize=(10,4))\n",
        "        order = df[c].value_counts().index\n",
        "        sns.countplot(x=c, data=df, order=order)\n",
        "        plt.title(f'Counts by {c}')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f'bar_{c}.png'))\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "KkWZSQYR7v92"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation heatmap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Keep only numeric columns with at least one non-NaN value\n",
        "numeric_cols_nonan = [c for c in numeric_cols if df[c].dropna().shape[0] > 0]\n",
        "\n",
        "if numeric_cols_nonan:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    corr = df[numeric_cols_nonan].corr()\n",
        "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "    plt.title('Correlation matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'correlation_heatmap.png'))\n",
        "    plt.close()\n",
        "else:\n",
        "    print(\"No valid numeric columns available for correlation heatmap.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH-Hq8GV7v6o",
        "outputId": "8be5f9e5-ff71-4982-d380-a212776a3bd5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No valid numeric columns available for correlation heatmap.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplots to inspect relationships (e.g., meals_served vs past_waste_kg)\n",
        "if 'meals_served' in df.columns and 'past_waste_kg' in df.columns:\n",
        "    plt.figure()\n",
        "    sns.scatterplot(x='meals_served', y='past_waste_kg', data=df)\n",
        "    plt.title('Meals served vs Past waste (kg)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'scatter_meals_vs_waste.png'))\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "HMwPMXRK7v3n"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation insights (basic)\n",
        "# -----------------------------\n",
        "if 'past_waste_kg' in df.columns and 'corr' in globals():\n",
        "    cor_with_waste = corr['past_waste_kg'].sort_values(ascending=False)\n",
        "    print('\\nCorrelation of numeric variables with past_waste_kg:')\n",
        "    print(cor_with_waste)\n"
      ],
      "metadata": {
        "id": "a4nYqDA876Vk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3823ec8"
      },
      "source": [
        "You can install Python libraries using `pip install` in a code cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df104e1f"
      },
      "source": [
        "!pip install <library_name>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aTJyq2-s76SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hypothesis testing\n",
        "# -----------------------------\n",
        "results = {}\n",
        "\n",
        "# 1) Special events (t-test)\n",
        "if 'special_event' in df.columns and 'past_waste_kg' in df.columns:\n",
        "    ev = df[df['special_event'] == 1]['past_waste_kg']\n",
        "    non = df[df['special_event'] == 0]['past_waste_kg']\n",
        "    # check normality roughly via sample size; use Welch's t-test\n",
        "    tstat, pval = stats.ttest_ind(ev.dropna(), non.dropna(), equal_var=False)\n",
        "    results['special_event_ttest'] = {\n",
        "        'tstat': float(tstat),\n",
        "        'pvalue': float(pval),\n",
        "        'mean_event': float(ev.mean()),\n",
        "        'mean_non_event': float(non.mean())\n",
        "    }\n",
        "    print('\\nSpecial event t-test: t={:.3f}, p={:.3f}'.format(tstat, pval))\n",
        "\n",
        "# 2) Kitchen staff levels (ANOVA)\n",
        "if 'staff_level' in df.columns and 'past_waste_kg' in df.columns:\n",
        "    groups = [g['past_waste_kg'].values for n, g in df.groupby('staff_level')]\n",
        "    fstat, pval = stats.f_oneway(*groups)\n",
        "    results['staff_level_anova'] = {'fstat': float(fstat), 'pvalue': float(pval)}\n",
        "    print('\\nANOVA across staff_level: F={:.3f}, p={:.3f}'.format(fstat, pval))\n",
        "\n",
        "# Save hypothesis results\n",
        "pd.DataFrame.from_dict(results, orient='index').to_csv(\n",
        "    os.path.join(OUTPUT_DIR, 'hypothesis_results.csv')\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Grouped summaries for reporting\n",
        "# -----------------------------\n",
        "if 'staff_level' in df.columns:\n",
        "    grp = df.groupby('staff_level')['past_waste_kg'].agg(['mean', 'median', 'count']).reset_index()\n",
        "    grp.to_csv(os.path.join(OUTPUT_DIR, 'waste_by_staff_level.csv'), index=False)\n",
        "\n",
        "if 'special_event' in df.columns:\n",
        "    ev_grp = df.groupby('special_event')['past_waste_kg'].agg(['mean', 'median', 'count']).reset_index()\n",
        "    ev_grp.to_csv(os.path.join(OUTPUT_DIR, 'waste_by_special_event.csv'), index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZCKuxWSM76PR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations generator (basic)\n",
        "# -----------------------------\n",
        "recs = []\n",
        "\n",
        "# Example rules\n",
        "if 'kitchen_staff' in df.columns and 'past_waste_kg' in df.columns:\n",
        "    # If higher staff levels produce lower waste on average -> suggest more staff during peaks\n",
        "    means = df.groupby('staff_level')['past_waste_kg'].mean()\n",
        "    if 'low' in means.index and 'high' in means.index and means['high'] < means['low']:\n",
        "        recs.append(\n",
        "            'Higher staff levels are associated with lower waste — consider increasing staff during busy days'\n",
        "        )\n",
        "\n",
        "if 'special_event' in df.columns and 'past_waste_kg' in df.columns:\n",
        "    ev_mean = df[df['special_event'] == 1]['past_waste_kg'].mean()\n",
        "    non_mean = df[df['special_event'] == 0]['past_waste_kg'].mean()\n",
        "    if ev_mean > non_mean:\n",
        "        recs.append(\n",
        "            'Special events show higher waste on average — implement event-specific portion control and donation planning'\n",
        "        )\n",
        "\n",
        "# Save recommendations\n",
        "with open(os.path.join(OUTPUT_DIR, 'recommendations.txt'), 'w') as f:\n",
        "    if recs:\n",
        "        f.write('\\n'.join(recs))\n",
        "    else:\n",
        "        f.write(\n",
        "            'No automated recommendations generated — please inspect visuals and correlations for context.'\n",
        "        )\n",
        "\n",
        "print('\\nEDA complete. Outputs saved in folder:', OUTPUT_DIR)\n",
        "print('Key recommendations written to', os.path.join(OUTPUT_DIR, 'recommendations.txt'))\n",
        "\n",
        "# -----------------------------\n",
        "# END\n",
        "# -----------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WntkUVLw8AWy",
        "outputId": "e19656e9-af8e-4ab3-81b3-7e4f79ce3798"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EDA complete. Outputs saved in folder: eda_outputs\n",
            "Key recommendations written to eda_outputs/recommendations.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tvoMJVBA8AQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfcjBG9A8AOA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}